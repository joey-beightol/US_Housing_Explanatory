{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "#### COMP4433\n",
    "#### Joseph Beightol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Description\n",
    "#### With data of your choice (apart from built-in data sources) use Plotly, Dash and any other required Python modules to build an interactive Dash application. This should be a user-facing application, so the final product should be reasonably well-polished and ready to be deployed.  \n",
    "\n",
    "#### While the first project in this course was exploratory in nature, this application should be more explanatory or should serve a specific purpose. For example, your final product might be used to convey relevant information to the user, provide an empirical solution to a question based on user input, or offer an interface for a user to intentionally engage with data on a topic of interest. \n",
    "\n",
    "#### Your final product should be a deployment-ready application. While deployment is not a requirement, you will be asked to provide a link to a GitHub repository with all the necessary materials to run your project in localhost.  \n",
    "\n",
    "#### The data that you use may be collected by your script. This can range in complexity from using pandas.read_csv() to pull a CSV from the web to making API calls to scraping. Be sure to include a data file or files for redundancy purposes.  Alternatively, you may strictly use static files. Note that the emphasis should be on your visualizations and communication, not the process through which your application gathers and ingests data. Ensure that the README in your project details any nuances that someone may need to know when executing your code. \n",
    "\n",
    "#### As with the first project, the aesthetics of your plots should be fine tuned to the extent that they reflect best practices discussed throughout the course, and relevant plot elements such as tick labeling, titles, descriptive string formatting and legends should be included as appropriate. \n",
    "\n",
    "Be sure to include: \n",
    "- At least four Dash Core Components (dropdowns, radio buttons, text entry fields, etc.) to ingest user input. \n",
    "- At least one callback decorator to achieve interactivity. \n",
    "- At least three different plots from Plotly. \n",
    "- Sufficient narrative and/or instructional information for users to be able to navigate the application and understand its intent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV, KFold\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "#pio.renderers.default='notebook_connected'\n",
    "pio.renderers.default='vscode'\n",
    "pio.templates.default = 'simple_white' \n",
    "import yfinance as yf\n",
    "pio.renderers.default='vscode'\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context #work around for SSL certificate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://www.zillow.com/research/data/\n",
    "\n",
    "https://www.kaggle.com/datasets/ahmedshahriarsakib/usa-real-estate-dataset\n",
    "\n",
    "https://fred.stlouisfed.org/series/MEHOINUSCOA646N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First step is to load in the datasets. We will first focus on the Zillow dataset to explore how the housing prices have increased over the years. Below we import four different datasets: City and Metro data for Single Family and Condo Homes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#City Data\n",
    "zillowCitySF= pd.read_csv('City_zhvi_uc_sfr_tier_0.33_0.67_sm_sa_month.csv') #city single family data\n",
    "zillowCitySF['HouseType'] = 'Single Family' #add column for house type and make it single family\n",
    "zillowCityCondo = pd.read_csv('City_zhvi_uc_condo_tier_0.33_0.67_sm_sa_month.csv') #city condo data\n",
    "zillowCityCondo['HouseType'] = 'Condo' #add column for house type and make it condo\n",
    "\n",
    "#Metro Data\n",
    "zillowMetroSF= pd.read_csv('Metro_zhvi_uc_sfr_tier_0.33_0.67_sm_sa_month.csv') #city single family data\n",
    "zillowMetroSF['HouseType'] = 'Single Family' #add column for house type and make it single family\n",
    "zillowMetroCondo = pd.read_csv('Metro_zhvi_uc_condo_tier_0.33_0.67_sm_sa_month.csv') #city condo data\n",
    "zillowMetroCondo['HouseType'] = 'Condo' #add column for house type and make it condo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concatenate DF into one large set\n",
    "zillowCombined = pd.concat([zillowCityCondo, zillowCitySF, zillowMetroCondo, zillowMetroSF], ignore_index=True) #concatenate the dataframes vertically\n",
    "zillowCombined.drop(columns=['RegionID', 'SizeRank', 'State', 'Metro', 'CountyName'], inplace=True) #drop unnecessary columns\n",
    "usHousing = zillowCombined[zillowCombined['RegionType'] == 'country'] #set US housing by grabbing only data from the \n",
    "zillowCombined = zillowCombined[zillowCombined['RegionType'] != 'country'] #drop rows that are for all US\n",
    "zillowCombined.head() #display first few rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to fill na values with regressor model\n",
    "def fill_missing_rows_numeric(df):\n",
    "    numDF = df.select_dtypes(include=[np.number]) #only look at numeric values\n",
    "    \n",
    "    for idx in range(len(numDF)):  #iterate through rows\n",
    "        row = numDF.iloc[idx]  #grab the row data\n",
    "        knownValues = row.dropna()  #grab the known values\n",
    "        missingDate = row[row.isna()].index  #grab dates (columns) with missing data\n",
    "\n",
    "        if len(missingDate) > 0 and len(knownValues) > 1:  #if missing and enough known values\n",
    "            X_train = np.arange(len(knownValues)).reshape(-1, 1)  #x-train\n",
    "            y_train = knownValues.values  #y-train\n",
    "            X_pred = np.arange(len(row)).reshape(-1, 1)[row.isna()]  #predicted\n",
    "            #model=RandomForestRegressor(random_state=42) #<------- for slower but more accurate results\n",
    "            model = LinearRegression()  #set model as linear regressor\n",
    "            model.fit(X_train, y_train)  #fit the model\n",
    "            predictions = model.predict(X_pred)  #predict missing values\n",
    "            numDF.loc[idx, missingDate] = predictions  #replace missing data\n",
    "\n",
    "    df.update(numDF)  #update df\n",
    "    return df #return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill na values\n",
    "zillowPredictCombined = fill_missing_rows_numeric(zillowCombined)\n",
    "zillowPredictCombined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillowCombined = zillowCombined.melt(\n",
    "    id_vars=['RegionName', 'RegionType', 'StateName', 'HouseType'], \n",
    "    var_name='Date', \n",
    "    value_name='Price'\n",
    ")\n",
    "\n",
    "zillowPredictCombined = zillowPredictCombined.melt(\n",
    "    id_vars=['RegionName', 'RegionType', 'StateName', 'HouseType'], \n",
    "    var_name='Date', \n",
    "    value_name='Price'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillowCombined.dropna(inplace=True)\n",
    "zillowCombined['Date'] = pd.to_datetime(zillowCombined['Date'])\n",
    "zillowPredictCombined.dropna(inplace=True)\n",
    "zillowPredictCombined['Date'] = pd.to_datetime(zillowPredictCombined['Date'])\n",
    "\n",
    "zillowCO = zillowCombined[zillowCombined['StateName']=='CO'] #grab only data with Colorado\n",
    "zillowCOPredict = zillowPredictCombined[zillowPredictCombined['StateName']=='CO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medHouseIncomeCO = pd.read_csv('MEHOINUSCOA646N.csv') #colorado median house income\n",
    "medHouseIncomeCO.rename(columns={'MEHOINUSCOA646N': 'Price', 'observation_date': 'Date'}, inplace=True) #rename columns\n",
    "medHouseIncomeCO.tail() #look at end of data to see where the date ends\n",
    "\n",
    "#grab starting from 2000\n",
    "medHouseIncomeCO['Date'] = pd.to_datetime(medHouseIncomeCO['Date']) #switch to date type\n",
    "medHouseIncomeCO = medHouseIncomeCO[medHouseIncomeCO['Date'].dt.year >= 2000]  #only grab years from 2000 on\n",
    "medHouseIncomeCO.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate data\n",
    "zillowSingleFamilyCO = zillowCO[zillowCO['HouseType']=='Single Family'] #grab single family colorado homes\n",
    "zillowCondoCO = zillowCO[zillowCO['HouseType']=='Condo'] #grab condo colorado homes\n",
    "\n",
    "#Melt data to have date be a column\n",
    "zillowMeltedSFCO = zillowSingleFamilyCO.melt(\n",
    "    id_vars=['RegionName', 'RegionType', 'StateName', 'HouseType'], \n",
    "    var_name='Date', \n",
    "    value_name='Price'\n",
    ")\n",
    "\n",
    "zillowMeltedCondoCO = zillowCondoCO.melt(\n",
    "    id_vars=['RegionName', 'RegionType', 'StateName', 'HouseType'], \n",
    "    var_name='Date', \n",
    "    value_name='Price'\n",
    ")\n",
    "\n",
    "#Convert Date column to datetime format\n",
    "zillowMeltedSFCO['Date'] = pd.to_datetime(zillowMeltedSFCO['Date'])\n",
    "zillowMeltedCondoCO['Date'] = pd.to_datetime(zillowMeltedCondoCO['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianPriceCO = zillowCOMelted.groupby('Date')['Price'].median().reset_index() #create new dataframe\n",
    "medianPriceCO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianPriceCO = medianPriceCO[medianPriceCO['Date'].dt.month == 1] #only grab info for January\n",
    "medianPriceCO['Date'] = pd.to_datetime(medianPriceCO['Date']).dt.strftime('%Y-%m') #change format of how to display date for median housing price\n",
    "medianPriceCO = medianPriceCO[pd.to_datetime(medianPriceCO['Date']).dt.year <= 2023] #grab data that is before or in 2023 (remove 2024)\n",
    "medHouseIncomeCO['Date'] = pd.to_datetime(medHouseIncomeCO['Date']).dt.strftime('%Y-%m') #change format of how to display date for median income\n",
    "medianPriceCO['Date'] = pd.to_datetime(medianPriceCO['Date']) #change format to datetime object\n",
    "medHouseIncomeCO['Date'] = pd.to_datetime(medHouseIncomeCO['Date']) #change format to datetime object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis on House Features and Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtorDF= pd.read_csv('realtor-data.zip.csv') #load in data\n",
    "realtorDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtorDF.drop(columns=['prev_sold_date', 'status', 'brokered_by', 'street'],inplace=True)\n",
    "realtorDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtorCO = realtorDF[realtorDF['state']=='Colorado'] #grab subset for colorado\n",
    "len(realtorCO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realtorCO = realtorCO.dropna() #drop all missing values\n",
    "realtorCO.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(6, 6)) #initiate plot\n",
    "corrMat = realtorCO.corr(numeric_only=True) #create correlation matrix\n",
    "mask = np.triu(np.ones_like(corrMat, dtype=bool)) #only care about bottom half\n",
    "sns.heatmap(corrMat, square=True, annot=True, cbar=True, cmap='crest', mask=mask, linewidths=0.5) #create heatmap to visualize strength of correlation\n",
    "plt.tight_layout\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab top correlated features\n",
    "realtorCONum = realtorCO[['price', 'bed', 'bath', 'acre_lot', 'house_size']]\n",
    "corr_df = realtorCONum.corr().stack().reset_index().rename(columns = {'level_0':'variable1', \n",
    "                                                            'level_1':'variable2', \n",
    "                                                             0:'correlation'})\n",
    "corr_df = corr_df[corr_df.variable2 > corr_df.variable1]\n",
    "corr_df = corr_df.loc[corr_df.correlation.abs().sort_values(ascending= False).index]\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for plotly visualization\n",
    "1. scatter plot of income vs housing price\n",
    "2. animation of home cost over the years for states and areas of colorado\n",
    "3. Map of prices by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for dash\n",
    "1. callback function to look at realtor data to see how different home characteristics affect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
